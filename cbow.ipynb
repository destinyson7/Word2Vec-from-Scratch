{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "cbow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEsL_-TwHWME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqSEwiX-HWML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "23a4d61f-7977-4cd9-c1d7-b8b665360362"
      },
      "source": [
        "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-13 14:15:55--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495854086 (473M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Electronics_5.json.gz’\n",
            "\n",
            "reviews_Electronics 100%[===================>] 472.88M  15.2MB/s    in 35s     \n",
            "\n",
            "2020-09-13 14:16:31 (13.6 MB/s) - ‘reviews_Electronics_5.json.gz’ saved [495854086/495854086]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXCxJ2G2HWMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import gzip\n",
        "\n",
        "filename = 'reviews_Electronics_5.json.gz' \n",
        "json_content = []\n",
        "with gzip.open(filename , 'rb') as gzip_file:\n",
        "    for line in gzip_file:  # Read one line.\n",
        "\n",
        "        line = line.rstrip()\n",
        "        if line:  # Any JSON data on it?\n",
        "            obj = json.loads(line)\n",
        "\n",
        "            json_content.append(obj['reviewText'])\n",
        "            \n",
        "            if len(json_content) == 50000:\n",
        "                break\n",
        "\n",
        "# print(json.dumps(json_content, indent=4))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZe083LzHWMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# json_content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxfNMbxwH5HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(data):\n",
        "    return re.split(r\"[^A-Za-z0-9]+\", data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBK-4_BAIuSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"25\".lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wlic9e1SikX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [re.sub(r'[!?]', '.', review) for review in json_content]\n",
        "data2 = []\n",
        "for sent in data:\n",
        "    for x in sent.split(\".\"):\n",
        "        if x.strip():\n",
        "            data2.append(x.strip())\n",
        "data = data2\n",
        "# data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3wMmwD7HWMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5db3659c-2421-40fe-ea0c-7581173e7c5d"
      },
      "source": [
        "data = [re.sub(r'[,!?;-]', '.', sent) for sent in data]\n",
        "data = [tokenize(sent) for sent in data]\n",
        "\n",
        "data = [[ch.lower() for ch in sent if ch.isalpha() or ch == '.'] for sent in data]\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "freq = defaultdict(int)\n",
        "\n",
        "def getfrequencies(data):\n",
        "    for sent in data:\n",
        "         for token in sent:\n",
        "            freq[token] += 1\n",
        "        \n",
        "getfrequencies(data)\n",
        "\n",
        "def remove_less_frequent(data_old):\n",
        "    data = []\n",
        "    for sent in data_old:\n",
        "         cur_sent = [token for token in sent if freq[token] > 5]\n",
        "         \n",
        "         if len(cur_sent) > 0:\n",
        "             data.append(cur_sent)\n",
        "                \n",
        "    return data\n",
        "    \n",
        "data = remove_less_frequent(data)\n",
        "\n",
        "number_of_tokens = 0\n",
        "for sent in data:\n",
        "    number_of_tokens += len(sent)\n",
        "print(\"Number of tokens:\", number_of_tokens)\n",
        "\n",
        "# data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens: 2079908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0apZwJNPZw1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPcyjj1cHWMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import linalg\n",
        "from collections import defaultdict\n",
        "\n",
        "epoch = -1\n",
        "def get_vectors(data, word2Ind, V, C):\n",
        "    global epoch\n",
        "#     epoch = -1\n",
        "    samples = 0\n",
        "    while True:\n",
        "        epoch += 1\n",
        "        print(f\"new epoch {epoch}, samples are {samples}\")\n",
        "        \n",
        "#         if epoch == 5:\n",
        "#             exit(0)\n",
        "\n",
        "        for sent in data:\n",
        "            prob = np.random.uniform(0, 1)\n",
        "\n",
        "            if prob > 0.4:\n",
        "                continue\n",
        "\n",
        "            len_sent = len(sent)\n",
        "\n",
        "            for i in range(len_sent):\n",
        "                y = np.zeros(V)\n",
        "                y[word2Ind[sent[i]]] = 1\n",
        "\n",
        "\n",
        "                x = np.zeros(V)\n",
        "                mean_cnt = 0\n",
        "                for j in range(max(0, i - C), min(i + C + 1, len_sent)):\n",
        "                    if j != i:\n",
        "                        x[word2Ind[sent[j]]] += 1\n",
        "                        mean_cnt += 1\n",
        "\n",
        "                if mean_cnt > 0:\n",
        "                    x /= mean_cnt\n",
        "\n",
        "                samples += 1\n",
        "                yield x, y\n",
        "\n",
        "batches = 0\n",
        "def get_batches(data, word2Ind, V, C, batch_size):\n",
        "    global batches\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    for x, y in get_vectors(data, word2Ind, V, C):\n",
        "        # print(\"here\")\n",
        "        while len(batch_x) < batch_size:\n",
        "            batch_x.append(x)\n",
        "            batch_y.append(y)\n",
        "        else:\n",
        "            batches += 1\n",
        "            # print(batches)\n",
        "            yield np.array(batch_x).T, np.array(batch_y).T\n",
        "            batch = []\n",
        "\n",
        "def get_dict(data):\n",
        "    words = set([])\n",
        "    for sent in data:\n",
        "        for token in sent:\n",
        "            words.add(token)\n",
        "    words = sorted(list(words))\n",
        "    n = len(words)\n",
        "    idx = 0\n",
        "    word2Ind = {}\n",
        "    Ind2word = {}\n",
        "    for k in words:\n",
        "        word2Ind[k] = idx\n",
        "        Ind2word[idx] = k\n",
        "        idx += 1\n",
        "    return word2Ind, Ind2word"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe0qKfs5HWMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48382928-dae7-4875-a511-7b380a06f7c5"
      },
      "source": [
        "word2Ind, Ind2word = get_dict(data)\n",
        "V = len(word2Ind)\n",
        "print(\"Size of vocabulary: \", V)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary:  9019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAS3GSldVaYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_training_data(data, word2Ind, V, C):\n",
        "#     global epoch\n",
        "#     X = []\n",
        "#     Y = []\n",
        "#     epoch = -1\n",
        "    \n",
        "#     for x, y in get_vectors(data, word2Ind, V, C):\n",
        "#       if epoch == 1:\n",
        "#         break\n",
        "#       X.append(x)\n",
        "#       Y.append(Y)\n",
        "\n",
        "#     X = np.array(X)\n",
        "#     Y = np.array(Y)\n",
        "\n",
        "#     return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNgSiHBaVhYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X, Y = get_training_data(data, word2Ind, V, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d362Vn-1SuZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epoch = -1\n",
        "# for x, y in get_batches(data, word2Ind, V, 3, 128):\n",
        "#   if epoch == 6:\n",
        "#     break\n",
        "#     # pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-efVg1bwUcaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxv56s-1HWMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # example of word to index mapping\n",
        "# print(\"Index of the word 'king' :  \",word2Ind['king'] )\n",
        "# print(\"Word which has index 2743:  \",Ind2word[2743] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrZzxriBHWMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model(N,V):\n",
        "  \n",
        "    W1 = np.random.rand(N, V)\n",
        "    W2 = np.random.rand(V, N)\n",
        "    b1 = np.random.rand(N, 1)\n",
        "    b2 = np.random.rand(V, 1)\n",
        "\n",
        "    return W1, W2, b1, b2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuPKxnm8HWMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(z):\n",
        "    e_z = np.exp(z)\n",
        "    yhat = e_z/np.sum(e_z, axis=0)\n",
        "    return yhat"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-OuhQZjHWMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(x, W1, W2, b1, b2):\n",
        "    h = np.dot(W1, x) + b1\n",
        "    # h = np.maximum(0, h)\n",
        "    z = np.dot(W2, h) + b2\n",
        "    return z, h"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Trjv7OHWMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eps = 1e-10\n",
        "def compute_cost(y, yhat, batch_size):\n",
        "    logprobs = np.multiply(np.log(yhat + eps),y) + np.multiply(np.log(1 - yhat + eps), 1 - y)\n",
        "    cost = -10 * np.sum(logprobs)\n",
        "    cost = np.squeeze(cost)\n",
        "    return cost"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAenk_TfHWMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size):\n",
        "    l1 = np.dot(W2.T, yhat - y)\n",
        "    # l1 = np.maximum(l1, 0)\n",
        "    grad_W1 = np.dot(l1, x.T) / batch_size\n",
        "    grad_W2 = np.dot(yhat - y, h.T) / batch_size\n",
        "    grad_b1 = np.sum(l1, axis = 1, keepdims = True) / batch_size\n",
        "    grad_b2 = np.sum(yhat - y, axis = 1, keepdims = True) / batch_size\n",
        "    \n",
        "    return grad_W1, grad_W2, grad_b1, grad_b2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMXNNkfuHWMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "costs = []\n",
        "\n",
        "def gradient_descent(data, word2Ind, N, V, num_iters, alpha=0.03):\n",
        "    global costs\n",
        "    W1, W2, b1, b2 = initialize_model(N, V)\n",
        "    batch_size = 256\n",
        "    iters = 0\n",
        "    C = 3\n",
        "    for x, y in get_batches(data, word2Ind, V, C, batch_size):\n",
        "        z, h = forward_prop(x, W1, W2, b1, b2)\n",
        "        yhat = softmax(z)\n",
        "        cost = compute_cost(y, yhat, batch_size)\n",
        "        costs.append(cost)\n",
        "        \n",
        "        if ((iters+1) % 10 == 1):\n",
        "            print(f\"iters: {iters + 1} cost: {cost:.12f}\")\n",
        "        \n",
        "        grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size)\n",
        "\n",
        "        W1 -= alpha * grad_W1 \n",
        "        W2 -= alpha * grad_W2\n",
        "        b1 -= alpha * grad_b1\n",
        "        b2 -= alpha * grad_b2\n",
        "\n",
        "        \n",
        "        iters += 1 \n",
        "        if iters == num_iters: \n",
        "            break\n",
        "        if iters % 100 == 0:\n",
        "            alpha *= 0.66\n",
        "            \n",
        "    return W1, W2, b1, b2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StusBHbTHWMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = 3\n",
        "N = 100\n",
        "word2Ind, Ind2word = get_dict(data)\n",
        "V = len(word2Ind)\n",
        "num_iters = 240000\n",
        "print(\"Call gradient_descent\")\n",
        "W1, W2, b1, b2 = gradient_descent(data, word2Ind, N, V, num_iters, 0.03)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "axes = plt.plot(costs)\n",
        "plt.ylim(0, 10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tol6rneRBPJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2eb079eb-6ddd-4a54-a7e1-5a52e0f1a511"
      },
      "source": [
        "W2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38435372, 0.42447199, 0.82103233, ..., 0.71661822, 0.54792843,\n",
              "        0.97807928],\n",
              "       [0.44532166, 0.68786715, 0.09882211, ..., 0.32850059, 0.7522977 ,\n",
              "        0.18998135],\n",
              "       [0.22457577, 0.73915263, 0.91651081, ..., 0.97168771, 0.36568035,\n",
              "        0.81263412],\n",
              "       ...,\n",
              "       [0.54045888, 0.04603386, 0.70633335, ..., 0.63795372, 0.3660147 ,\n",
              "        0.63182383],\n",
              "       [0.8279313 , 0.06105092, 0.55871708, ..., 0.11467812, 0.76364993,\n",
              "        0.01626806],\n",
              "       [0.15397381, 0.03347262, 0.89411425, ..., 0.27012268, 0.1518555 ,\n",
              "        0.22288167]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61OtLTG_BqJj",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}